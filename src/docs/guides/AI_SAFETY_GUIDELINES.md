# AI Safety Guidelines

**Version:** 1.0  
**Last Updated:** November 6, 2025  
**Status:** üìã Mandatory for Phase 6

---

## ‚ö†Ô∏è Critical Safety Principles

**Before deploying AI to production, ALL team members must understand:**

1. **üõ°Ô∏è AI augments humans, never replaces accountability**
2. **üìä Shadow mode is mandatory before assist mode**
3. **üö® Kill switches must be tested weekly**
4. **üìù Every AI decision must be explainable**
5. **üîÑ Learning from humans is continuous**

---

## üö¶ When to Use Each Mode

### **Shadow Mode (Always Start Here)**

**Use when:**
- ‚úÖ First time deploying AI for a tenant
- ‚úÖ Testing new model version
- ‚úÖ New approval policy type
- ‚úÖ After major code changes
- ‚úÖ After accuracy drop >2%

**Duration:** Minimum 2 weeks OR 1000+ decisions

**Success Criteria:**
- Agreement rate ‚â•70%
- Zero critical errors
- Team reviewed and approved

**Do NOT skip shadow mode!**

---

### **Assist Mode (Human in Loop)**

**Use when:**
- ‚úÖ Shadow mode completed successfully
- ‚úÖ Agreement rate ‚â•80%
- ‚úÖ Team trained on AI suggestions
- ‚úÖ Override tracking working

**Duration:** Minimum 2 weeks

**Success Criteria:**
- Agreement rate ‚â•80%
- User satisfaction ‚â•8/10
- Override rate stable (<20%)

**Red flags to watch:**
- Humans blindly accepting AI suggestions (educate users!)
- Agreement rate dropping over time
- Specific user overriding >50% (investigate why)

---

### **Auto Mode (Supervised Automation)**

**Use when:**
- ‚úÖ Assist mode completed successfully
- ‚úÖ Agreement rate ‚â•85%
- ‚úÖ Zero critical errors in 30 days
- ‚úÖ Kill switch tested
- ‚úÖ Safety caps configured

**Start conservatively:**
- Week 1: Max 10 auto-approvals/day
- Week 2: Max 25/day (if accuracy ‚â•99%)
- Month 2+: Dynamic based on rolling accuracy

**Never auto-approve:**
- ‚ùå New contractors (<30 days)
- ‚ùå Amounts >$5k (without explicit approval)
- ‚ùå Timesheets with flags
- ‚ùå When confidence <85%

---

## üö® Kill Switch Procedures

### **When to Activate Kill Switch:**

**Immediate (within 5 minutes):**
- üî¥ Auto-approval error rate >5% in last hour
- üî¥ Critical error (wrong amount, wrong person)
- üî¥ Webhook failures >10% in last hour
- üî¥ Anomaly rate >50% in last hour

**Within 1 hour:**
- üü° Agreement rate drops >5% from baseline
- üü° Multiple user complaints
- üü° Unexpected model behavior

**Planned (maintenance):**
- üü¢ Before deploying new model version
- üü¢ Before major code changes
- üü¢ During high-risk periods (year-end, audits)

---

### **How to Activate Kill Switch:**

**Via API:**
```bash
curl -X POST https://api.workgraph.com/admin/tenants/{id}/ai/disable \
  -H "Authorization: Bearer $ADMIN_TOKEN" \
  -d '{"reason": "Error rate too high", "disabledBy": "ops-team"}'
```

**Via Dashboard:**
1. Go to Admin ‚Üí Tenants ‚Üí [Tenant Name]
2. Click "AI Settings"
3. Click "Emergency Stop"
4. Enter reason
5. Confirm

**Via Database (emergency):**
```sql
UPDATE tenant
SET settings = jsonb_set(settings, '{ai_mode}', '"assist"'::jsonb)
WHERE id = 'tenant-id';
```

---

### **After Activating Kill Switch:**

**Immediately:**
1. ‚úÖ Verify AI mode switched to `assist`
2. ‚úÖ Verify no pending auto-approvals
3. ‚úÖ Post in #incidents Slack
4. ‚úÖ Alert engineering team

**Within 1 hour:**
1. ‚úÖ Root cause analysis
2. ‚úÖ Review last 100 AI decisions
3. ‚úÖ Check for incorrect auto-approvals
4. ‚úÖ Notify affected users if needed

**Within 24 hours:**
1. ‚úÖ Fix root cause
2. ‚úÖ Add regression test
3. ‚úÖ Update monitoring/alerts
4. ‚úÖ Document incident in postmortem

**Before re-enabling:**
1. ‚úÖ Confirm fix deployed
2. ‚úÖ Run shadow mode for 24h
3. ‚úÖ Get approval from engineering lead
4. ‚úÖ Monitor closely for 48h

---

## üìä Monitoring Requirements

### **Must Monitor (Real-Time):**

```
Auto-approval rate      ‚Üí Alert if >20% or <5%
Agreement rate          ‚Üí Alert if drops >5%
Override rate           ‚Üí Alert if >30%
Error rate              ‚Üí Alert if >2%
Webhook success rate    ‚Üí Alert if <95%
DLQ depth               ‚Üí Alert if >10
Confidence distribution ‚Üí Alert if p50 <0.7
```

### **Must Review (Daily):**

```
Top 10 overrides        ‚Üí Why did humans disagree?
Low confidence items    ‚Üí Are we routing correctly?
Anomaly patterns        ‚Üí Are we flagging correctly?
Feature importance      ‚Üí Is model using right signals?
```

### **Must Review (Weekly):**

```
Agreement trend         ‚Üí Improving or degrading?
Override breakdown      ‚Üí By user, by project, by amount
Model drift metrics     ‚Üí Is accuracy stable?
Safety cap utilization  ‚Üí Should we increase caps?
```

---

## üéØ Decision Checklist

### **Before Enabling AI for a Tenant:**

- [ ] Tenant has ‚â•100 historical approvals
- [ ] Shadow mode ran for ‚â•2 weeks
- [ ] Agreement rate ‚â•70% in shadow mode
- [ ] Zero critical errors in shadow mode
- [ ] Team trained on AI features
- [ ] Kill switch tested
- [ ] Alerts configured
- [ ] Tenant explicitly opted in
- [ ] Legal/compliance approved

### **Before Switching Shadow ‚Üí Assist:**

- [ ] Shadow mode criteria met
- [ ] Team reviewed AI suggestions and approved
- [ ] UI shows AI confidence clearly
- [ ] Override tracking working
- [ ] Users trained on how to override
- [ ] Agreement rate ‚â•80%

### **Before Switching Assist ‚Üí Auto:**

- [ ] Assist mode ran for ‚â•2 weeks
- [ ] Agreement rate ‚â•85%
- [ ] Zero critical errors in 30 days
- [ ] Safety caps configured (start at 10/day)
- [ ] Kill switch tested this week
- [ ] Ops team on-call and aware
- [ ] Users notified about auto-approvals
- [ ] Audit trail verified working

---

## ‚öñÔ∏è Compliance & Audit

### **Every AI Decision Must:**

1. **Be logged** to `ai_decision` table
2. **Include explanation** (human-readable reason)
3. **Store features** used (for reproducibility)
4. **Link to approval** record
5. **Track overrides** (for learning)

### **Audit Trail Requirements:**

```sql
-- Must be able to answer these questions:
-- 1. What did AI decide?
SELECT decision, score, confidence FROM ai_decision WHERE id = ?;

-- 2. Why did AI decide that?
SELECT explanation, features FROM ai_decision WHERE id = ?;

-- 3. What rules were triggered?
SELECT flags FROM ai_decision WHERE id = ?;

-- 4. What model version was used?
SELECT model_version_id FROM ai_decision WHERE id = ?;

-- 5. Did human agree?
SELECT human_override, human_decision FROM ai_decision WHERE id = ?;

-- 6. Can we reproduce this decision?
-- Yes - features + model_version + rules ‚Üí same decision
```

### **Compliance Checklist:**

- [ ] GDPR: Right to explanation (provided via `explanation` field)
- [ ] GDPR: Right to human review (always available via override)
- [ ] GDPR: Data minimization (only necessary features stored)
- [ ] SOC 2: Audit trail (complete and immutable)
- [ ] SOC 2: Access controls (RBAC on AI settings)
- [ ] SOC 2: Change management (model versioning)
- [ ] SOX: Segregation of duties (AI can't change rules)

---

## üß™ Testing Requirements

### **Before Deploying to Production:**

**Unit Tests:**
- [ ] Feature extraction (100+ test cases)
- [ ] Rule evaluation (50+ test cases)
- [ ] Safety caps (edge cases)
- [ ] Kill switch (activation + deactivation)

**Integration Tests:**
- [ ] Shadow mode flow
- [ ] Assist mode flow
- [ ] Auto mode flow
- [ ] Override tracking
- [ ] Audit logging

**E2E Tests:**
- [ ] Submit timesheet ‚Üí AI evaluates ‚Üí logs decision
- [ ] Submit timesheet ‚Üí AI approves ‚Üí event emits ‚Üí audit logged
- [ ] AI suggests ‚Üí human overrides ‚Üí override logged
- [ ] Kill switch ‚Üí all pending auto-approvals cancelled

**Chaos Tests:**
- [ ] Model service down ‚Üí fallback to human
- [ ] Database slow ‚Üí timeout handled gracefully
- [ ] Webhook fails ‚Üí retry logic works
- [ ] High load (1000 req/s) ‚Üí no errors

---

## üîê Security Considerations

### **Principle: AI Has Same Permissions as Users**

```typescript
// Before AI approves, check permissions
async function checkAIPermissions(
  projectId: string,
  timesheetId: string
): Promise<boolean> {
  
  // Would the assigned manager be able to approve this?
  const manager = await getAssignedManager(projectId);
  const canApprove = await checkPermission(
    manager.id,
    'approval.approve',
    projectId
  );
  
  if (!canApprove) {
    console.warn('AI cannot approve - manager lacks permission');
    return false;
  }
  
  return true;
}
```

### **Security Checklist:**

- [ ] AI decisions respect RBAC
- [ ] AI cannot escalate privileges
- [ ] AI cannot modify approval policies
- [ ] AI cannot access PII unless necessary
- [ ] AI decisions are tamper-proof (immutable audit log)
- [ ] Model weights stored securely
- [ ] Training data access controlled

---

## üéì Team Training Requirements

### **All Team Members Must:**

- [ ] Complete "AI Safety 101" training
- [ ] Understand shadow/assist/auto modes
- [ ] Know how to activate kill switch
- [ ] Know how to override AI suggestions
- [ ] Understand when to escalate

### **Approvers Must:**

- [ ] Understand AI confidence scores
- [ ] Know when to trust AI vs review manually
- [ ] Understand override impact (AI learns from it)
- [ ] Report suspicious AI behavior

### **Ops Team Must:**

- [ ] Monitor AI metrics daily
- [ ] Respond to alerts within SLA
- [ ] Perform weekly kill switch test
- [ ] Conduct monthly model drift review

### **Engineering Team Must:**

- [ ] Review AI code changes thoroughly
- [ ] Run full test suite before deploy
- [ ] Monitor rollout closely (48h)
- [ ] Conduct postmortems on incidents

---

## üöÄ Rollout Strategy

### **Phase 1: Internal Testing (2 weeks)**

- Enable shadow mode for 1 internal project
- Team uses system daily
- Collect feedback
- Fix issues

### **Phase 2: Pilot Tenant (2 weeks)**

- Select 1 friendly tenant
- Enable shadow mode
- Review daily
- Transition to assist mode if successful

### **Phase 3: Gradual Rollout (4 weeks)**

- Week 1: 5 tenants (shadow mode)
- Week 2: 10 tenants (assist mode for successful ones)
- Week 3: 25 tenants
- Week 4: 50 tenants (auto mode for proven ones)

### **Phase 4: General Availability (Ongoing)**

- New tenants start in shadow mode
- Opt-in for auto mode after 30 days
- Continuous monitoring

---

## ‚ö†Ô∏è Common Pitfalls to Avoid

### **1. Skipping Shadow Mode**

**Don't:** "We're confident in our model, let's go straight to auto!"  
**Do:** Always start with shadow mode, no exceptions.

### **2. Ignoring Overrides**

**Don't:** "Users are just being conservative."  
**Do:** Investigate every override. Humans see things AI misses.

### **3. Setting Caps Too High**

**Don't:** "Let's auto-approve 1000/day from day 1!"  
**Do:** Start at 10/day, increase gradually based on accuracy.

### **4. Not Testing Kill Switch**

**Don't:** "We'll test it if we need it."  
**Do:** Test weekly. If it doesn't work in practice, it doesn't work.

### **5. Trusting AI Blindly**

**Don't:** "99% accuracy is good enough."  
**Do:** 1% error on 10,000 approvals/month = 100 mistakes. Unacceptable.

### **6. Poor Explanations**

**Don't:** "score: 0.87" (unhelpful)  
**Do:** "Auto-approved: amount under $1k, no anomalies, contractor has 95% approval rate"

### **7. No Rollback Plan**

**Don't:** "We'll figure it out if things go wrong."  
**Do:** Document exact steps to revert to previous state.

---

## üìû Incident Response

### **Severity Levels:**

**P0 (Critical):**
- Incorrect auto-approval (wrong amount, wrong person)
- PII leak via AI explanation
- AI bypass RBAC

**P1 (High):**
- Auto-approval error rate >10%
- Kill switch not working
- Audit trail gaps

**P2 (Medium):**
- Agreement rate drop >10%
- Webhook failures affecting users
- Model drift detected

**P3 (Low):**
- Single override anomaly
- UI confusion about AI suggestions
- Documentation gaps

### **Response Times:**

- P0: Immediate (kill switch), resolve within 2h
- P1: Respond within 30m, resolve within 4h
- P2: Respond within 2h, resolve within 24h
- P3: Respond within 24h, resolve within 1 week

---

## ‚úÖ Pre-Launch Checklist

**Before launching AI to production:**

### **Technical:**
- [ ] All tests passing (unit, integration, E2E, chaos)
- [ ] Monitoring & alerts configured
- [ ] Kill switch tested this week
- [ ] Audit logging verified
- [ ] Performance tested (1000 req/s)
- [ ] Security review completed
- [ ] Code review completed

### **Operational:**
- [ ] On-call schedule updated
- [ ] Runbook documented
- [ ] Incident response plan ready
- [ ] Escalation paths defined
- [ ] Team trained

### **Compliance:**
- [ ] Legal review completed
- [ ] Privacy impact assessment done
- [ ] Audit trail verified
- [ ] Data retention policy documented

### **User Experience:**
- [ ] UI shows AI confidence clearly
- [ ] Override is easy
- [ ] Explanations are helpful
- [ ] Users trained
- [ ] Support documentation ready

---

## üéØ Success Metrics

**Month 1 Goals:**
- Shadow mode: Agreement rate ‚â•70%
- Assist mode: Agreement rate ‚â•80%
- Auto mode: Zero critical errors

**Month 3 Goals:**
- Auto-approval rate: ‚â•10%
- Agreement rate: ‚â•85%
- Time saved: ‚â•50%
- User satisfaction: ‚â•8/10

**Month 6 Goals:**
- Auto-approval rate: ‚â•25%
- Agreement rate: ‚â•90%
- Time saved: ‚â•70%
- Cost per approval: -80%

---

## üìö Required Reading

Before working on AI features, read:

1. **[AI Decision Architecture](../architecture/AI_DECISION_ARCHITECTURE.md)**
2. **[Google's Rules of ML](https://developers.google.com/machine-learning/guides/rules-of-ml)**
3. **[Stripe Radar Case Study](https://stripe.com/radar/guide)**
4. **[Model Cards Paper](https://arxiv.org/abs/1810.03993)**

---

## üéâ Remember

**AI is a tool, not a replacement.** 

The goal is to:
- ‚úÖ Save time on routine decisions
- ‚úÖ Let humans focus on edge cases
- ‚úÖ Learn continuously from feedback
- ‚úÖ Maintain trust and transparency

**NOT to:**
- ‚ùå Replace human judgment
- ‚ùå Hide how decisions are made
- ‚ùå Optimize for speed over accuracy
- ‚ùå Deploy without thorough testing

**When in doubt, be conservative.** It's better to route to a human than to auto-approve incorrectly.

---

**Document Version:** 1.0  
**Status:** Mandatory Reading  
**Owner:** Engineering + Product + Legal
